---
tags:
  - LeetCode
---

# [2322. Minimum Score After Removals on a Tree](https://leetcode.com/problems/minimum-score-after-removals-on-a-tree/description/)  

+ 日期 : 2025/07/24  

## 問題描述  

給定一個有 `n` 個節點且 `n-1` 個邊的 `graph`，以及代表各節點數值的 `nums`，  
請拆掉兩個邊，得出三個連接圖，將連接圖各自的所有節點值用 `XOR` 計算，  
然後計算出三個中，最大的 `XOR` 值與最小的 `XOR` 值的差，取出所有可能內，最小的結果。  

## 直覺想法  

Don't waste your time.  

+ [HINT](https://leetcode.com/problems/minimum-score-after-removals-on-a-tree/description/comments/3091256/)  

1. 先使用 `DFS` 計算從該節點作為 `root` 時，該子樹的 `XOR` 值。  
2. 為了判斷節點在哪個子樹中，做 `DFS` 時，紀錄進出節點的時間。  
3. 先固定一刀後，遍歷所有節點找出第二刀，並計算結果。  

我浪費我的時間，卡在第三關，然後我後悔了。  

```cpp=
/* The code I failed */
class Solution {
public:
    int minimumScore(vector<int>& nums, vector<vector<int>>& edges) {
        int n = nums.size();
        vector<vector<int>> adj(n);
        for(vector<int> e : edges) {
            int a = e[0];
            int b = e[1];
            adj[a].push_back(b);
            adj[b].push_back(a);
        }
        vector<int> subRoot(n); // [XOR, time]
        vector<pair<int, int>> inout(n, {-1, -1});
        int time = 0;
        dfs(adj, subRoot, inout, nums, 0, -1, time);
        int res = INT_MAX;
        for(int i = 0; i < n; ++i) {
            cout << inout[i].first << "," << inout[i].second << "\n";
            int comp1 = subRoot[i];
            int comp2 = subRoot[0] ^ comp1;
            for(int j = 0; j < n; ++j) {
                if(i == j || j == 0)  continue;
                int comp3 = subRoot[j];
                if(inout[j].first > inout[i].first && inout[j].second == inout[i].second) {
                    // subtree of comp1
                    comp1 ^= comp3;
                } else {
                    comp2 ^= comp3;
                }
                int score = max(comp1, max(comp2, comp3)) - min(comp1, min(comp2, comp3));
                res = min(res, score);
            }
        }
        return res;
    }
    
    int dfs(vector<vector<int>> &adj, vector<int> &subRoot, vector<pair<int, int>> &inout,
        vector<int> &nums, int node, int pre,int &time) {
        int res = nums[node];
        inout[node].first = time;
        time += 1;
        for(int i = 0; i < adj[node].size(); ++i) {
            if(adj[node][i] == pre) continue;
            res ^= dfs(adj, subRoot, inout, nums, adj[node][i], node, time);
        }
        subRoot[node] = res;
        inout[node].second = time;
        return res;
    }
};
```

## 題解  

```cpp=
class Solution {
public:
    int calc(int part1, int part2, int part3) {
        return max(part1, max(part2, part3)) - min(part1, min(part2, part3));
    }
    int minimumScore(vector<int>& nums, vector<vector<int>>& edges) {
        int n = nums.size(), cnt = 0;
        vector<int> sum(n), in(n), out(n);
        vector<vector<int>> adj(n);
        for (auto& e : edges) {
            adj[e[0]].push_back(e[1]);
            adj[e[1]].push_back(e[0]);
        }
        function<void(int, int)> dfs = [&](int x, int fa) {
            in[x] = cnt++;
            sum[x] = nums[x];
            for (auto& y : adj[x]) {
                if (y == fa) {
                    continue;
                }
                dfs(y, x);
                sum[x] ^= sum[y];
            }
            out[x] = cnt;
        };

        dfs(0, -1);
        int res = INT_MAX;
        for (int u = 1; u < n; u++) {
            for (int v = u + 1; v < n; v++) {
                if (in[v] > in[u] && in[v] < out[u]) {
                    res = min(res,
                              calc(sum[0] ^ sum[u], sum[u] ^ sum[v], sum[v]));
                } else if (in[u] > in[v] && in[u] < out[v]) {
                    res = min(res,
                              calc(sum[0] ^ sum[v], sum[v] ^ sum[u], sum[u]));
                } else {
                    res = min(res,
                              calc(sum[0] ^ sum[u] ^ sum[v], sum[u], sum[v]));
                }
            }
        }
        return res;
    }
};
```

Time Complexity : $O(n^2)$  
Space Complexity : $O(n)$  

## 心得  

I'm ready for working at McDonald's.  
